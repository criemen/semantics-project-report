% !TEX root = main.tex
\section{Implementation of a Dataflow Library in QL for SSA-dIMP}

In this section, we describe an implementation of the algorithm described in the
last section.
The implementation is written in QL.
As part of the project, we implemented a library and a database scheme for SSA-dIMP.
On top of that, the dataflow algorithm is implemented.

The implementation itself is very easy, but the structure follows the
dataflow library used for Java.
It is useful, because it demonstrates how to bridge the gap between
the theoretical description of the algorithm with the soundness proof
as in \autoref{sec:df-theory} and the actual implementation of dataflow
in QL for languages like Java.
However, all the features that complicate the dataflow library for Java have been 
omitted.
The most complicated feature is that the Java dataflow library supports tracking 
flow through fields, i.e.\ if a variable that received data from a source 
is assigned to a field in an object, and a sink later reads from that field,
dataflow is detected.
Furthermore, the Java dataflow library is an interprocedural analysis.
Thus, the implementation has to be done very carefully to exhibit good
performance on large projects.

\subsection{The Database Scheme}
The database scheme is given in full in the \hyperref[lst:dbscheme]{appendix}.
The database contains a representation the abstract syntax tree (AST) of the program.
For each arithmetic expression, its unique ID, its kind
(i.e.\ integer literal, addition, multiplication, \ldots) 
and the ID of the type of the expression are saved.
Furthermore, another table contains the parent-child relation for arithmetic 
expressions - every tuple there contains the ID of an expression parent 
(either an arithmetic expression, a Boolean expression or a statement),
the ID of the child arithmetic expression and the index.
For example the addition $a_0 + a_1$ has as first child the ID of the expression 
$a_0$, and as second child the ID of the expressions $a_1$.
The order of these is an implementation detail of the database scheme in combination
with the extractor (that writes the database) and the standard library 
(that is built on top of the database scheme).

A similar database layout is employed for statements and Boolean expressions.
Expressions like literals have another relation that tracks the actual value of the
literal, variable reads have a relation that tracks the variable that is read,
variable assignments have a relation that tracks the variable that is assigned to, etc.

The database scheme is quite close how a compiler would model an AST for SSA-dIMP.
It is certainly inspired by the QL database scheme for Java.
There is one crucial difference though - in SSA-dIMP the AST is already in SSA form,
and we assume that sets $\Gamma, \Delta$ exist to prove that.
Programs in Java are not in SSA form.
Thus, as part of the QL library for Java, there exists an SSA construction algorithm
that synthesizes an SSA form.
As this is computed on the fly, it is not represented in the database scheme.

Essentially, this makes the implementation of the library for SSA-dIMP easier,
as we dont have to deal with the SSA construction.
Constructing the SSA form of a program is a well-researched problem in compiler
construction, so we feel confident that assuming the existence of an SSA form 
of the program does not lower the value of this project.

\subsection{The Standard Library}
The standard library for SSA-dIMP is implemented in the file \hyperref[lst:library]{library.qll}.

The standard library offers an object-oriented interface on top of the relational
database scheme.
Again, this interface is inspired by the corresponding library for Java.

The library offers interfaces for arithmetic expressions, and each kind of expression
has a sub-class available in the standard library.
As the QL language requires toString predicates on all classes,
the standard library also provides pretty-printing for the entire AST.

Furthermore, for example the class representing a Variable offers access to the
reads of that variable (phi nodes and variable access expressions), as well
as access to the statements that assign to this variable.
Also, the parent-child relation is exposed, and used to implement named helper predicates.
For example, for an if statement, the child branches are exposed as \texttt{getThenBranch()}
and \texttt{getElseBranch()}.
This hides the implementation detail that the then branch is the first child of the
if statement, and the else branch the second.

\subsection{The Dataflow Algorithm}
\subsubsection*{The Dataflow Graph}
As the algorithm in \autoref{sec:df-theory} computes a type for all expressions and statements in the program,
it implicitly runs on the AST.
However, typing the whole program, while nice from the theoretical perspective, is 
inefficient if we want to only detect the possibility of dataflow.

The algorithm in practice as given in \hyperref[lst:dataflow]{dataflow.qll} runs on a subset of the AST.
Furthermore, it uses a graph structure we call the \emph{dataflow graph} to keep
track of which expressions and statements potentially get data from a source.
The nodes of that graph are made up by all expressions of kind variable access and source,
statements and phi nodes of the program.
We can restrict the node set to these expression kinds, as all other expression kinds
are always tagged with $\lclean$, and thus never take part in a dataflow computation.
The node set contains  exactly the relevant elements of the AST that are involved in determining
if a program has dataflow or not.

We define the \texttt{flowStep} relation on the node set.
It can be understod as the edge set of the dataflow graph and implements the
essence of the typing rules.
A big difference to the typing rules is that we do not distinguish between $\ltracked$ and $\lunknown$,
we only have one kind of edge that indicates that tracked data potentially flows 
from one node to another.

We can understand the typing problem as a graph problem, as the insight is that
dataflow always includes two (different) steps - there has to be a source at which 
the tracked value is introduced, and there has to be a sink which reads the tracked value.
Without either, the program is safe.

By looking at the typing rule for statements, we see that only assign and sink statements
use the tracking marker assigned to the arithmetic expression used in that statement.
Thus, there is an edge from the right-hand side of an assignment (the expression) 
to the node for the assign statement, as well as from the operand from the sink 
to the node for the sink statement.

The other cases in \texttt{flowStep} take care of tracking variables.


By looking at the typing rule for expression, we see that only expressions that possibly 
result in a non-clean marker are source expressions and variable reads.
Both get special treatment in \texttt{flowStep} - sources because we do not care
if something flows to a source,
as the result will always have a tracked marker anyways.
Thus, sources are not handled in \texttt{flowStep} at all.
Sources are later considered, though.
The tracked marker for variable reads is fully determined by the type context,
which we only implicitly compute.



A node in the dataflow graph has an incoming edge if:
It is of type expression and it has type $\ltracked$ or $\lunknown$.
The only exception to this are sources that don't have incoming edges.
It is of type statement, and the statement is the parent of an expression that has type
$\ltracked$ or $\lunknown$.



As last step, the predicate \texttt{reaches}
computes the transitive closure of \texttt{flowStep}, beginning with all nodes
that are source expressions.

\subsection{The Query}
The query is given in \hyperref[lst:query]{query.ql}.
It is very simple, it outputs a list of pairs of sources and sinks if the
sink is reachable from the source.
If the list is empty, the program is safe and it is guaranteed by~\autoref{thm:soundness-df}
that the program has no dataflow.
If the list is not empty, no assertion about the program correctness can be given.
