% !TEX root = main.tex
\section{Formalization of Dataflow with IMP}

In this section, we are going to formalize what we mean by dataflow,
give a simple algorithm for computing dataflow and proving it is sound.
We will furthermore use this formalization to prove that our
path-sensitivity extension of the dataflow algorithm preserves soundness.

We use the toy language IMP as presented in~\cite{sat}.
The lecture notes themselves heavily borrow from~\cite{fsopl} for the
presentation and semantics of IMP.
We assume that the reader is familiar with the syntax and semantics of IMP
as presented in section 2.1 of~\cite{sat}.

\subsection{Syntax and Semantic of dIMP}
We extend the syntax of IMP a little bit
and call the resulting language dIMP (for dataflow IMP):
\begin{align*}
    &a \Coloneqq \dots | \textbf{source } a\\
    &c \Coloneqq \dots | \textbf{sink } a\\
\end{align*}
We define the set $\tilde{\textbf{Z}} = \textbf{Z} \cup \{\top_n | n \in \textbf{Z}\}$.
Stores are denoted with $\sigma \in \Sigma = \textbf{Loc} \to \tilde{\textbf{Z}}$.
Furthermore, only up to one expression of the form $\textbf{source } a$ is allowed
in a program.
This technical restriction makes the later definition of a minimal dataflow graph
easier. It could be lifted by indexing the $\top_n$ per source.

The intuition here is that for all $n \in \textbf{Z}$, $\top_n$
is a marker indicating that the value $n$ is tracked by the dataflow algorithm,
and all tracked values originate at the source (see the semantics below).
The command $\textbf{sink } a$ is a special marker for the dataflow sink.
In real programs, the dataflow source would likely be a procedure reading input,
i.e.\ from a terminal, and the dataflow sink would likely be a procedure 
printing the data to a terminal, or otherwise communicating with the outside world.
Note that stores can now contain both regular integers as variable values,
as well as dataflow-tracked values.

The judgements are extended as follows:

Judgment $\langle a, \sigma \rangle \downarrow n$:
\begin{align*}
    \textsc{EA-Source}\ddfrac{\langle a, \sigma \rangle \downarrow n}
    {\langle \textbf{source }a, \sigma \rangle \downarrow \top_n}
    \qquad     
    \textsc{EA-Untracking}\ddfrac{\langle a, \sigma \rangle \downarrow \top_n}
    {\langle a, \sigma \rangle \downarrow n}
\end{align*}




Judgment $\langle c, \sigma \rangle \downarrow \sigma'$:
\begin{align*}
    &\textsc{EC-Sink1}\ddfrac{\langle a, \sigma \rangle\downarrow \top_n}
    {\langle \textbf{sink } a, \sigma \rangle \downarrow \sigma}\\
    &\textsc{EC-Sink2}\ddfrac{\langle a, \sigma\rangle \downarrow n}
    {\langle \textbf{sink } a, \sigma \rangle \downarrow \sigma}
    (\text{Only if $\langle a, \sigma\rangle$ doesn't evaluate to $\top_n$, too})
\end{align*}

The rule \textsc{EC-Assign} is removed and replaced by:
\begin{align*}
    &\textsc{EC-Assign1}\ddfrac{\langle a, \sigma\rangle \downarrow \top_n}
    {\langle X \coloneqq a, \sigma \rangle \downarrow \sigma[X \mapsto \top_n]}\\
    &\textsc{EC-Assign2}\ddfrac{\langle a, \sigma \rangle \downarrow n}
    {\langle X \coloneqq a, \sigma \rangle \downarrow \sigma[X \mapsto n]}
     (\text{Only if $\langle a, \sigma\rangle$ doesn't evaluate to $\top_n$, too})
\end{align*}

Note that the side-conditions on \textsc{EC-Sink2} and \textsc{EC-Assign2}
ensure that all derivations are unique.
Furthermore, the rule \textsc{EA-Untracking} ensures that whenever the value of
a tracked arithmetic expression is used in a non-value-preserving operation,
the value is not tracked anymore.
This applies even to operations like addition with 0 or multiplication with 1,
that are value-preserving special cases of non-value-preserving operations.
The \textbf{sink} command has the same semantics as \textbf{skip} 
for program execution.
However, the difference will become obvious when defining dataflow.

\subsection{Definition of Dataflow}
\begin{definition}[Program]
    A \emph{program} in IMP is a command $c$.
    Complex programs are expressed by using the recursive nature of
    the definition of commands.
\end{definition}

\begin{definition}[Initial Store]
    An \emph{initial store} is a store $\sigma_0$ s.t.\ 
    $\forall X: \exists n: \sigma_0(X) = n$.
    This means that an initial store is not allowed to contain dataflow tracking 
    markers of the form $\top_n$.
    We will implicitly denote inital stores by $\sigma_0$.
\end{definition}

\begin{definition}[Dataflow]
    A tuple $(c, \sigma_0)$ of a program $c$ and initial store $\sigma_0$ 
    has \emph{dataflow from the source to a sink} if the derivation $\E$
    of $\langle c, \sigma_0 \rangle \downarrow \sigma'$ contains a 
    subderivation using rule \textsc{EC-Sink1}.
\end{definition}
\begin{remark}
    Note that a technicality of this definition is that only terminating programs
(with $\sigma_0$) can have dataflow. 
In a practical setting, this is not correct - a program could have
interesting dataflow from a source to a sink, and then enter an infinite loop.
However, there would be a (terminating) sub-program that we could analyze.
\end{remark}

\begin{definition}[Dataflow Algorithm]
    A \emph{dataflow algorithm} $\A(c)$ computes, given a program $c$,
    if there exists an initial store $\sigma_0$ 
    such that $(c, \sigma_0)$ has dataflow from the source to a sink.
\end{definition}

\begin{definition}[Soundness]
    A dataflow algorithm is \emph{sound} if for any tuple $(c, \sigma_0)$ that
    has dataflow it holds that $\A(c) = \text{HAS\_FLOW}$.
\end{definition}

\begin{definition}[Completeness]
    A dataflow algorithm is \emph{complete} if $\A(c) = \text{HAS\_FLOW}$
    implies that there exists an initial store $\sigma_0$
     such that $(c, \sigma_0)$ has dataflow.
\end{definition}
\begin{definition}[False Positive]
    A program $c$ for which there exists no initial store $\sigma_0$ such that 
    $(c, \sigma_0)$ has dataflow, but for which $\A(c) = \text{HAS\_FLOW}$ holds
    is called a \emph{false positive} of the algorithm.
\end{definition}
\begin{remark}
    In general, it is impossible to construct a dataflow algorithm that is both 
    sound and complete.
    In practice, a dataflow algorithm will be neither sound nor complete.
    However, in the theoretic section of this chapter, we are interested in 
    sound dataflow algorithms.
    The \emph{trivially sound dataflow algorithm} $\A_0(c) = \text{HAS\_FLOW}$ 
    is sound by definition, but not very interesting.
    We will not consider it further, but it is interesting to keep in mind,
    because it shows that just showing that a dataflow algorithm is sound does not
    mean it is an interesting algorithm.    
\end{remark}

\subsection{The Dataflow Graph}
To aid the construction of dataflow algorithms, we define the concept
of a (directed) dataflow graph.
Then we show that an algorithm that outputs HAS\_FLOW if 
there exists a path from the source 
node to a sink node in a dataflow graph and NO\_FLOW otherwise
is a sound dataflow algorithm.
Furthermore, we introduce an algorithm to compute a dataflow graph.

The \emph{node set} $V$ of the \emph{minimal dataflow graph} $G_\text{min}(c)$
is defined on the syntactic structure
of $c$. It is a subset of the node set of the abstract syntax tree
(every node knows about its location in the program text).
Every (sub-)command of $c$, as well as any arithmetic expression $a$ in the 
program is a node in the dataflow graph.
For example for
$c = \textbf{skip}; (\textbf{skip}; x \coloneqq \bar{4} + y)$
the node set consists of $c$ itself, the first \textbf{skip}, the command 
$\textbf{skip}; x \coloneqq \bar{4} + y$, the second \textbf{skip} (that is different 
from the first because it appears in another location), the command
$x \coloneqq \bar{4} + y$, and the arithmetic expressions $\bar{4}+y$,
$\bar{4}$ and $y$.

For every initial store $\sigma_0$, 
let $\E$ be a bigstep derivation of $\langle c, \sigma_0 \rangle \downarrow \sigma'$.
The edge set $E^0_{\sigma_0}$ contains the following edges:
\begin{enumerate}
    \item $\E$ contains a subderivation
    \begin{equation*}
        \E_1 = \textsc{EC-Assign1}\ddfrac{\overset{\E'}{\langle a, \sigma \rangle \downarrow \top_n}}
        {\langle X \coloneqq a, \sigma \rangle \downarrow
         \sigma[X \mapsto \top_n]}
    \end{equation*}
    Then there is an edge from $a$ to the node of $X \coloneqq a$.
    This case includes both outgoing edges from sources and variable reads
    of locations to which a tracked value was written to.
    \item $\E$ contains a subderivation
    \begin{equation*}
        \E_1 = \textsc{EC-Sink1}\ddfrac{\overset{\E'}{\langle a, \sigma \rangle \downarrow \top_n}}
        {\langle \textbf{sink }a, \sigma \rangle \downarrow
         \sigma}
    \end{equation*}
    Then there is an edge from $a$ to the node of $\textbf{sink }a$.
    \item
    $\E$ contains a subderivation
    \begin{equation*}
        \E_1 = \textsc{EA-Loc}\ddfrac{}
        {\langle X, \sigma[X \mapsto \top_n] \rangle \downarrow \top_n}
    \end{equation*}
    and a subderivation
    \begin{equation*}
        \E_2 = \textsc{EC-Assign1}\ddfrac{\overset{\E'}{\langle a, \sigma' \rangle \downarrow \top_n}}
        {\langle X \coloneqq a, \sigma' \rangle \downarrow
         \sigma'[X \mapsto \top_n]}
    \end{equation*}
    Then there is an edge from the store $X \coloneqq a$ to the read node $X$ as 
    refered to by $\E_1$.
    Technical note: Here we exploit the fact that there is only one source ---
    else this case could introduce edges between unrelated paths if two sources for the same 
    $\sigma_0$ would evaluate to $\top_n$. Then the edge set would not be minimal
    anymore.
\end{enumerate}

Based on that we define the (minimized) edge set $E^1_{\sigma_0}$
that contains an edge from $E^0_{\sigma_0}$ iff it is part of a path 
from a node of the form $\textbf{source }a$
to a node of the form $\textbf{sink }a$.

Then we define the \emph{edge set} of the minimal dataflow graph as
\begin{equation*}
    E = \bigcup_{\sigma_0} E^1_{\sigma_0}
\end{equation*}
Even though the union is over an infinite set, the result is finite
as $E \subseteq V \times V$ and $|V| < \infty$.

We call a graph a \emph{dataflow graph} if it has the node set as the minimal
dataflow graph and its edge set contains the edges of the minimal dataflow 
graph.

Let $\A_{G_\text{min}}(c)$ be the algorithm that takes the
minimal dataflow graph $G_\text{min}(c)$ and outputs HAS\_FLOW if there 
exists a node of the form 
$\textbf{source }a$ and a node $\textbf{sink }a$ such that there is a path in 
$G_\text{min}(c)$ from the source node to the sink node.
If no such path exists, it outputs NO\_FLOW.



\begin{theorem}
    \label{thm:min-dg}
    The algorithm $\A_{G_\text{min}}(c)$ is a sound dataflow algorithm.
\end{theorem}
\begin{proof}
    Let $\sigma_0$ be an initial store such that $(c, \sigma_0)$ has dataflow.
    If no such $\sigma_0$ exists, by the definition of soundness
    the proof is concluded.

    \begin{claim}
        The edges in $E^0_{\sigma_0}$ contain a path from the source to a sink.
    \end{claim}
    \begin{claimproof}
        We proof the claim by induction over ????.

        Let $\E$ be the bigstep derivation of
        $\langle c, \sigma_0 \rangle \downarrow \sigma'$.
        By the definition that $(c, \sigma_0)$ has dataflow, there exists a
        subderivation of $\E$ that has shape
        \begin{equation*}
            \E^* = \textsc{EC-Sink1}
            \ddfrac{\overset{\E_1}{\langle a, \sigma \rangle\downarrow \top_n}}
            {\langle \textbf{sink } a, \sigma \rangle \downarrow \sigma}
        \end{equation*}
        By definition, there is an edge from $a$ to the sink $E^1_{\sigma_0}$.
        Looking at the bigstep rules, $\E_1$ can have two shapes.\\
        \textbf{Case 1:}
        \begin{equation*}
            \E_1 = \textsc{EA-Source}
            \ddfrac{\overset{\E_2}{\langle a, \sigma \rangle \downarrow n}}
            {\langle \textbf{source }a, \sigma \rangle \downarrow \top_n}
        \end{equation*}
        But then due to rule (1) there is an edge between the source and sink 
        and we're done.\\
        \textbf{Case 2:}
        \begin{equation*}
            \E_1 = \textsc{EA-Loc}\ddfrac{}
            {\langle X, \sigma[X \mapsto \top_n] \rangle \downarrow \top_n}
        \end{equation*}

    \end{claimproof}
    As $G_\text{min}(c)$ contains for any $\sigma_0$ the edges of $E^1_{\sigma_0}$,
    this is enough to show the theorem.
\end{proof}

\begin{corollary}
    \label{cor:dg-sound}
    For any dataflow graph $G(c)$ the algorithm $\A_{G}(c)$ is a sound
     dataflow algorithm.
\end{corollary}
\begin{proof}
    Remember that any dataflow graph contains the minimal dataflow graph as 
    subgraph. Thus for every pair $(c, \sigma_0)$ that has dataflow
    there is a path from the source node to a sink node, 
    thus $\A$ reports flow by~\autoref{thm:min-dg}.
    It doesn't matter if $G$ has more edges for soundness.
\end{proof}

\begin{remark}
    The \emph{minimal} dataflow graph gets name by being the minimal dataflow graph
    among all dataflow graphs that are considered in this paper.
    It should also be (by construction) the smallest graph $G$ on the node set 
    such that $\A_G(c)$ is a sound dataflow algorithm.
    However, we do not attempt to prove this property.
\end{remark}

\begin{remark}
    Note that not all (sound) dataflow algorithms have the form $\A_G(c)$.
    For example the trivially sound dataflow algorithm disagrees on the 
    program $\textbf{skip}$ with any dataflow algorithm of the form 
    $\A_G(c)$ - the trivially sound
    dataflow algorithm outputs HAS\_FLOW, whereas
    $A_G(\textbf{skip}) = \text{NO\_FLOW}$ because the node set contains
    neither source nor sink.
\end{remark}

\subsection{The Dataflow Algorithm}
TODO algorithm description for DFG algorithm.
Then: Thm that that algorithm actually computes a superset of the edge set of 
the DF graph, thus by~\autoref{cor:dg-sound} it is a sound dataflow algorithm.


\subsection{A Path-Sensitive Dataflow Algorithm}
TODO: description of path-pruning, proof that the only pruned edges are not
in the definition of the minimal dataflow graph

%However, as a dataflow algorithm cannot be sound and complete at the same time,
%dataflow algorithms constitute an heuristic.
%The evaluation of heuristics in a theoretic setting is difficult.
%We do aim to show that 
% TODO: A_2 is better than A_1, as both sound+one has less FP
